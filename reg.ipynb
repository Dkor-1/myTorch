{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f104df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.16821801417752186), np.float64(0.3438032402351199))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def prediction(theta_0, theta_1, x):\n",
    "    \"\"\"주어진 학습 데이터 벡터 x에 대해서 모든 예측 값을 벡터로 리턴하는 함수\"\"\"\n",
    "    # 지난 실습의 코드를 여기에 붙여 넣으세요\n",
    "    return theta_0 + theta_1 * x\n",
    "    \n",
    "def prediction_difference(theta_0, theta_1, x, y):\n",
    "    \"\"\"모든 예측 값들과 목표 변수들의 오차를 벡터로 리턴해주는 함수\"\"\"\n",
    "    # 지난 실습의 코드를 여기에 붙여 넣으세요\n",
    "    return prediction(theta_0, theta_1, x) -  y\n",
    "    \n",
    "def gradient_descent(theta_0, theta_1, x, y, iterations, alpha):\n",
    "    \"\"\"주어진 theta_0, theta_1 변수들을 경사 하강를 하면서 업데이트 해주는 함수\"\"\"\n",
    "    for _ in range(iterations):  # 정해진 번만큼 경사 하강을 한다\n",
    "        error = prediction_difference(theta_0, theta_1, x, y)  # 예측값들과 입력 변수들의 오차를 계산\n",
    "        # 여기에 코드를 작성하세요\n",
    "        theta_0 -= alpha * error.mean()\n",
    "        theta_1 -= alpha * (error * x).mean()\n",
    "    return theta_0, theta_1\n",
    "    \n",
    "    \n",
    "# 입력 변수(집 크기) 초기화 (모든 집 평수 데이터를 1/10 크기로 줄임)\n",
    "house_size = np.array([0.9, 1.4, 2, 2.1, 2.6, 3.3, 3.35, 3.9, 4.4, 4.7, 5.2, 5.75, 6.7, 6.9])\n",
    "\n",
    "# 목표 변수(집 가격) 초기화 (모든 집 값 데이터를 1/10 크기로 줄임)\n",
    "house_price = np.array([0.3, 0.75, 0.45, 1.1, 1.45, 0.9, 1.8, 0.9, 1.5, 2.2, 1.75, 2.3, 2.49, 2.6])\n",
    "\n",
    "# theta 값들 초기화 (아무 값이나 시작함)\n",
    "theta_0 = 2.5\n",
    "theta_1 = 0\n",
    "\n",
    "# 학습률 0.1로 200번 경사 하강\n",
    "theta_0, theta_1 = gradient_descent(theta_0, theta_1, house_size, house_price, 200, 0.1)\n",
    "\n",
    "theta_0, theta_1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40e8cb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.236881612652454"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "boston_df = pd.read_csv('boston.csv')\n",
    "\n",
    "y = boston_df['MEDV']\n",
    "X = boston_df.drop('MEDV',axis=1)\n",
    "\n",
    "x = pd.DataFrame(X['AGE'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=5)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_test_prediction = model.predict(x_test)\n",
    "\n",
    "sqrt(mean_squared_error(y_test , y_test_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667bb0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.568292042303157"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "boston_df = pd.read_csv('boston.csv')\n",
    "\n",
    "y = boston_df['MEDV']\n",
    "X = boston_df.drop('MEDV',axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=5)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_test_prediction = model.predict(X_test)\n",
    "\n",
    "sqrt(mean_squared_error(y_test , y_test_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c24ff178",
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUFuncTypeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     43\u001b[39m theta = np.array([\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m])\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# 학습률 0.01로 100번 경사 하강\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m theta = \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m theta\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mgradient_descent\u001b[39m\u001b[34m(X, theta, y, iterations, alpha)\u001b[39m\n\u001b[32m     14\u001b[39m     error = prediction(X, theta) - y\n\u001b[32m     16\u001b[39m     gradient = (X.T @ error) / m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[43mtheta\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m theta\n",
      "\u001b[31mUFuncTypeError\u001b[39m: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def prediction(X, theta):\n",
    "    \"\"\"다중 선형 회귀 가정 함수. 모든 데이터에 대한 예측 값을 numpy 배열로 리턴한다\"\"\"\n",
    "    # 지난 실습의 코드를 여기에 붙여 넣으세요\n",
    "    return X @ theta\n",
    "\n",
    "def gradient_descent(X, theta, y, iterations, alpha):\n",
    "    \"\"\"다중 선형 회귀 경사 하강법을 구현한 함수\"\"\"\n",
    "    m = len(X)  # 입력 변수 개수 저장\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        # 여기에 코드를 작성하세요\n",
    "        error = prediction(X, theta) - y\n",
    "\n",
    "        gradient = (X.T @ error) / m\n",
    "\n",
    "        theta -= alpha * gradient\n",
    "        \n",
    "    return theta\n",
    "    \n",
    "\n",
    "# 입력 변수\n",
    "house_size = np.array([1.0, 1.5, 1.8, 5, 2.0, 2.5, 3.0, 3.5, 4.0, 5.0, 6.0, 7.0, 8.0, 8.5, 9.0, 10.0])  # 집 크기\n",
    "distance_from_station = np.array([5, 4.6, 4.2, 3.9, 3.9, 3.6, 3.5, 3.4, 2.9, 2.8, 2.7, 2.3, 2.0, 1.8, 1.5, 1.0])  # 지하철역으로부터의 거리 (km)\n",
    "number_of_rooms = np.array([1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4])  # 방 수\n",
    "\n",
    "# 목표 변수\n",
    "house_price = np.array([3, 3.2, 3.6 , 8, 3.4, 4.5, 5, 5.8, 6, 6.5, 9, 9, 10, 12, 13, 15])  # 집 가격\n",
    "\n",
    "# 설계 행렬 X 정의\n",
    "X = np.array([\n",
    "    np.ones(16),\n",
    "    house_size,\n",
    "    distance_from_station,\n",
    "    number_of_rooms\n",
    "]).T\n",
    "\n",
    "# 목표 변수 y 정의\n",
    "y = house_price\n",
    "\n",
    "# 파라미터 theta 초기화\n",
    "theta = np.array([0, 0, 0, 0])\n",
    "\n",
    "# 학습률 0.01로 100번 경사 하강\n",
    "theta = gradient_descent(X, theta, y, 100, 0.01)\n",
    "\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09a650e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.603912902946895"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 라이브러리 import\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas as pd  \n",
    "\n",
    "# 당뇨병 데이터 갖고 오기\n",
    "diabetes_dataset = datasets.load_diabetes()\n",
    "\n",
    "# 입력 변수를 사용하기 편하게 pandas dataframe으로 변환\n",
    "X = pd.DataFrame(diabetes_dataset.data, columns=diabetes_dataset.feature_names)\n",
    "\n",
    "# 목표 변수를 사용하기 편하게 pandas dataframe으로 변환\n",
    "y = pd.DataFrame(diabetes_dataset.target, columns=['diabetes'])\n",
    "\n",
    "# 여기에 코드를 작성하세요\n",
    "\n",
    "# 평균 제곱 오차의 루트를 통해서 테스트 데이터에서의 모델 성능 판단\n",
    "# mse = mean_squared_error(y_test, y_test_predict)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=5)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_test_prediction = model.predict(X_test)\n",
    "\n",
    "sqrt(mean_squared_error(y_test , y_test_prediction))\n",
    "\n",
    "# mse ** 0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
